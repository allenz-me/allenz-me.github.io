---
title: "Bias and Variance Approximation in Value Function Estimates"
date: 2022-02-10
draft: true
slug: 8
categories: ["论文简读"]
tags: ["MS", "MDP"]
# 四个大类: 分析与概率, 算法与程序设计, 运筹与优化, 论文简读
---

发表在 Management Science, 2007. DOI: https://doi.org/10.1287/mnsc.1060.0614

Key words: value function; conﬁdence interval; variance; bias

Area of review: stochastic models and simulation

---

这篇文章研究有限状态无穷时段的MDP的统计估计的值函数的 bias and variance.



很多MDP我们没法知道真实的 transition probabilities 和 rewards，所以往往使用统计方法进行估计。Especially when only a finite sample of trajectories is available.

在 policy evalution 时，假定只有若干样本轨道，那么：

$$
\begin{aligned}
\hat{P}_{i j}^{a}=\frac{N_{i j}^{a}}{N_{i}^{a}}, \quad \hat{R}_{i j}^{a}=\frac{C_{i j}^{a}}{N_{i j}^{a}} , \quad \widehat{P}_{i j}^{\pi}=\sum_{a} \pi(a \mid i) \hat{P}_{i j}^{a} \\
\hat{R}_{i}^{a}=\sum_{j} \hat{P}_{i j}^{a} \hat{R}_{i j}^{a}=\frac{\sum_{j} C_{i j}^{a}}{N_{i}^{a}}, \quad \hat{R}_{i}^{\pi}=\sum_{a} \pi(a \mid i) \hat{R}_{i}^{a} \\
\end{aligned}
$$

以及值函数的近似估计：

$$
\widehat{Y}^{\pi}=\left(I-\alpha \hat{P}^{\pi}\right)^{-1} \hat{R}^{\pi}
$$

其中 $\alpha$ 是 dicount factor



文章主要研究了 $\hat{Y}^\pi$ 的 bias and variance，即 $\mathbb{E}[\hat{Y}]$ 和 $\operatorname{cov}(\hat{Y})$

令：
$$
\tilde{P} = \hat{P} - P, \qquad \tilde{R} = \hat{R} - R
$$
这时候我们得到：
$$
\mathbb{E}[\widehat{Y}]=\mathbb{E}\left[(I-\alpha(P+\widetilde{P}))^{-1}(R+\widetilde{R})\right]
$$
这里最重要的一步是用 $(I-\alpha P)^{-1}$ 去表示 $(I - \alpha(P + \tilde{P} ))^{-1}$ .

本质上这是在用 $A^{-1}$ 表示 $(A+B)^{-1}$ ，结果我网上一搜，真搜出来了：

参考：https://math.stackexchange.com/questions/17776/inverse-of-the-sum-of-matrices



以下是一些结论：
$$
\begin{aligned}
&(A+B)^{-1}=A^{-1}-A^{-1} B(A+B)^{-1} \\
&\Rightarrow (A+B)^{-1}=A^{-1}-A^{-1} B A^{-1}+A^{-1} B A^{-1} B A^{-1}-A^{-1} B A^{-1} B A^{-1} B A^{-1}+\cdots
\end{aligned}
$$

这个不等式就像 
$$
\frac{1}{a+b}=\frac{1}{\left(1+\frac{b}{a}\right) a}
$$
一样。



实际上，注意到:
$$
\begin{aligned}
(I - \alpha P - \alpha \tilde{P})^{-1} &= [(I-\alpha P)(I - (I-\alpha P)^{-1} \alpha \tilde{P})]^{-1} \\
& =[I - \alpha (I - \alpha P)^{-1} \tilde{P}]^{-1} (I - \alpha P)^{-1} \\
& = (I-\alpha P)^{-1} + \sum_{k=1}^\infty  [\alpha (I- \alpha P)^{-1} \tilde{P}]^k (I-\alpha P)^{-1}\\
\end{aligned}
$$
文章里证明的写法明显不是给人看的。




> Woodbury matrix identity
> $$
> (A+U C V)^{-1}=A^{-1}-A^{-1} U\left(C^{-1}+V A^{-1} U\right)^{-1} V A^{-1}
> $$
> 这个也是有用的结论



**文章经过长长的推导最终得到了 $\hat{Y}$ 的 bias and variance.** 这构成了文章的前两个 proposition



总而言之，$\hat{Y}$ 显然不是无偏的；文章的 proposition 3 给出了：
$$
\frac{\sigma\left(\widehat{Y}_{i}\right)}{\left|\mathbb{E}\left[\widehat{Y}_{i}\right]-Y_{i}\right|}=\Omega\left(\sqrt{N_{i^{*}}^{a^{*}}}\right) \quad \text { for all } i
$$
This proposition implies that the errors introduced by the parametric variance will generally be much larger than the bias.



接着，文章话锋一转，引出了一个更为重要的问题。


> The magnitude of $\mathbb{E}[\hat{Y}]$, and therefore the bias in this example, is studied in the order statistics literature (Leadbetter et al. 1983). We also refer readers to Clark (1961), which presents a procedure to approximate moments of the maximum of a finite number of correlated Gaussian random variables.



